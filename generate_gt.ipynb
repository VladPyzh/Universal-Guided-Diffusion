{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional, Union, Tuple\n",
    "from transformers import AutoModelForMaskGeneration, AutoProcessor, pipeline\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    xmin: int\n",
    "    ymin: int\n",
    "    xmax: int\n",
    "    ymax: int\n",
    "\n",
    "    @property\n",
    "    def xyxy(self) -> List[float]:\n",
    "        return [self.xmin, self.ymin, self.xmax, self.ymax]\n",
    "\n",
    "@dataclass\n",
    "class DetectionResult:\n",
    "    score: float\n",
    "    label: str\n",
    "    box: BoundingBox\n",
    "    mask: Optional[np.array] = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, detection_dict: Dict) -> 'DetectionResult':\n",
    "        return cls(score=detection_dict['score'],\n",
    "                   label=detection_dict['label'],\n",
    "                   box=BoundingBox(xmin=detection_dict['box']['xmin'],\n",
    "                                   ymin=detection_dict['box']['ymin'],\n",
    "                                   xmax=detection_dict['box']['xmax'],\n",
    "                                   ymax=detection_dict['box']['ymax']))\n",
    "\n",
    "def mask_to_polygon(mask: np.ndarray) -> List[List[int]]:\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Extract the vertices of the contour\n",
    "    polygon = largest_contour.reshape(-1, 2).tolist()\n",
    "\n",
    "    return polygon\n",
    "\n",
    "def polygon_to_mask(polygon: List[Tuple[int, int]], image_shape: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a polygon to a segmentation mask.\n",
    "\n",
    "    Args:\n",
    "    - polygon (list): List of (x, y) coordinates representing the vertices of the polygon.\n",
    "    - image_shape (tuple): Shape of the image (height, width) for the mask.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Segmentation mask with the polygon filled.\n",
    "    \"\"\"\n",
    "    # Create an empty mask\n",
    "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "\n",
    "    # Convert polygon to an array of points\n",
    "    pts = np.array(polygon, dtype=np.int32)\n",
    "\n",
    "    # Fill the polygon with white color (255)\n",
    "    cv2.fillPoly(mask, [pts], color=(255,))\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_boxes(results: DetectionResult) -> List[List[List[float]]]:\n",
    "    boxes = []\n",
    "    for result in results:\n",
    "        xyxy = result.box.xyxy\n",
    "        boxes.append(xyxy)\n",
    "\n",
    "    return [boxes]\n",
    "\n",
    "def refine_masks(masks: torch.BoolTensor, polygon_refinement: bool = False) -> List[np.ndarray]:\n",
    "    masks = masks.cpu().float()\n",
    "    masks = masks.permute(0, 2, 3, 1)\n",
    "    masks = masks.mean(axis=-1)\n",
    "    masks = (masks > 0).int()\n",
    "    masks = masks.numpy().astype(np.uint8)\n",
    "    masks = list(masks)\n",
    "\n",
    "    if polygon_refinement:\n",
    "        for idx, mask in enumerate(masks):\n",
    "            shape = mask.shape\n",
    "            polygon = mask_to_polygon(mask)\n",
    "            mask = polygon_to_mask(polygon, shape)\n",
    "            masks[idx] = mask\n",
    "\n",
    "    return masks\n",
    "\n",
    "class SegmentationEngine:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.detector_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "        self.object_detector = pipeline(model=self.detector_id, \n",
    "                                        task=\"zero-shot-object-detection\", \n",
    "                                        device=self.device)\n",
    "\n",
    "        self.segmenter_id = \"facebook/sam-vit-huge\"\n",
    "\n",
    "        self.segmentator = AutoModelForMaskGeneration.from_pretrained(self.segmenter_id).to(self.device)\n",
    "        self.seg_processor = AutoProcessor.from_pretrained(self.segmenter_id)\n",
    "\n",
    "\n",
    "    def detect(\n",
    "            self,\n",
    "            image: Image.Image,\n",
    "            labels: List[str],\n",
    "            threshold: float = 0.5,\n",
    "    ):\n",
    "        \n",
    "        labels = [label if label.endswith(\".\") else label+\".\" for label in labels]\n",
    "\n",
    "        results = self.object_detector(image,  candidate_labels=labels, threshold=threshold)\n",
    "        results = [DetectionResult.from_dict(result) for result in results]\n",
    "\n",
    "        return results\n",
    "\n",
    "    def segment(\n",
    "            self,\n",
    "            image: Image.Image,\n",
    "            detection_results: List[Dict[str, Any]],\n",
    "            polygon_refinement: bool = False,\n",
    "            segmenter_id: Optional[str] = None,\n",
    "    ):\n",
    "        boxes = get_boxes(detection_results)\n",
    "        inputs = self.seg_processor(images=image, input_boxes=boxes, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        outputs = self.segmentator(**inputs)\n",
    "        masks = self.seg_processor.post_process_masks(\n",
    "            masks=outputs.pred_masks,\n",
    "            original_sizes=inputs.original_sizes,\n",
    "            reshaped_input_sizes=inputs.reshaped_input_sizes\n",
    "        )[0]\n",
    "\n",
    "        masks = refine_masks(masks, polygon_refinement)\n",
    "\n",
    "        for detection_result, mask in zip(detection_results, masks):\n",
    "            detection_result.mask = mask\n",
    "\n",
    "        return detection_results\n",
    "\n",
    "\n",
    "    def grounded_segmentation(\n",
    "        self,\n",
    "        image: Union[Image.Image],\n",
    "        labels: List[str],\n",
    "        threshold: float = 0.3,\n",
    "        polygon_refinement: bool = False,\n",
    "    ) -> Tuple[np.ndarray, List[DetectionResult]]:\n",
    "\n",
    "        detections = self.detect(image, labels, threshold)\n",
    "        detections = self.segment(image, detections, polygon_refinement)\n",
    "\n",
    "        return np.array(image), detections\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentator = SegmentationEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "labels = [\"cat\", \"dog\", \"fox\"]\n",
    "idx = 2\n",
    "\n",
    "\n",
    "image_list = sorted(glob(f\"/job/dataset/{labels[idx]}/*.jpg\"))\n",
    "\n",
    "json_labeled = {}\n",
    "\n",
    "pipe = pipeline(\"image-text-to-text\", model=model_id, device_map=\"auto\")\n",
    "prompt = \"USER: <image>\\nDescribe what you see on this picture?\\nASSISTANT:\"\n",
    "\n",
    "for path in tqdm(image_list):\n",
    "    try:\n",
    "        image, pipe_res = segmentator.grounded_segmentation(Image.open(path).convert(\"RGB\"), labels=[labels[idx]])\n",
    "        plt.imsave(f\"/job/processed_data/{labels[idx]}/{os.path.basename(path)}\", image)\n",
    "        plt.imsave(f\"/job/processed_data/{labels[idx]}/{os.path.basename(path)[:-4]}_mask.jpg\", pipe_res[0].mask)\n",
    "\n",
    "        outputs = pipe(Image.fromarray(image), text=prompt, max_new_tokens=200)\n",
    "        json_labeled[os.path.basename(path)[:-4]] = outputs[0][\"generated_text\"].split(\"ASSISTANT:\")[-1]\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(path)\n",
    "    \n",
    "with open(f\"/job/processed_data/{labels[idx]}/annotations.json\", \"w\") as json_file:\n",
    "    json.dump(json_labeled, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
